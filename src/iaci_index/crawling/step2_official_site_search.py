# step2_selenium_full.py
# åŠŸèƒ½ï¼šä¸ºæ°‘åŠžæœ¬ç§‘é™¢æ ¡è‡ªåŠ¨å‘çŽ°å®˜ç½‘ URLï¼ˆæ”¯æŒæ–­ç‚¹ç»­è·‘ï¼‰

import time
import random
from pathlib import Path
from urllib.parse import quote

import pandas as pd
import requests

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options

# ================== åŸºæœ¬é…ç½® ==================

# Step1 è¾“å‡ºçš„æ°‘åŠžæœ¬ç§‘ Excelï¼ˆè¾“å…¥ï¼‰
INPUT_FILE = "step1_private_undergrad.xlsx"

# æœ¬è„šæœ¬çš„ç»“æžœæ–‡ä»¶ï¼ˆè¾“å‡º & æ–­ç‚¹ç»­è·‘ç”¨ï¼‰
OUTPUT_FILE = "step2_private_undergrad_with_urls_selenium.xlsx"

# ä½ çš„ chromedriver è·¯å¾„ â€”â€” å¿…é¡»æ”¹æˆä½ è‡ªå·±çš„
CHROMEDRIVER_PATH = r"E:\gwydata\pythonProject\drivers\chromedriver.exe"

# requests è§£æžè·³è½¬ç”¨çš„è¯·æ±‚å¤´
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/122.0 Safari/537.36"
    )
}

# ================== å·¥å…·å‡½æ•° ==================


def resolve_real_url(u: str) -> str:
    """
    æŠŠç™¾åº¦ link?url=... è¿™æ ·çš„è·³è½¬é“¾æŽ¥è§£æžæˆçœŸå®žå®˜ç½‘ï¼›
    å¦‚æžœä¸æ˜¯ baidu åŸŸåï¼Œç›´æŽ¥è¿”å›žï¼›
    å¦‚æžœè§£æžå¤±è´¥ï¼Œå°±è¿”å›žåŽŸå§‹é“¾æŽ¥å…œåº•ã€‚
    """
    if not u:
        return ""

    # å·²ç»ä¸æ˜¯ baidu åŸŸåï¼ŒåŸºæœ¬å¯ä»¥è§†ä¸ºçœŸå®žå®˜ç½‘
    if "baidu.com" not in u:
        return u

    try:
        r = requests.get(
            u, headers=HEADERS, timeout=5, allow_redirects=True
        )
        return r.url
    except Exception as e:
        print("  âš ï¸ è§£æžè·³è½¬å¤±è´¥ï¼Œå…ˆä¿ç•™ç™¾åº¦é“¾æŽ¥ï¼š", e)
        return u


def init_driver():
    """åˆå§‹åŒ– Selenium æµè§ˆå™¨"""
    chrome_options = Options()
    chrome_options.add_argument("--start-maximized")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option(
        "excludeSwitches", ["enable-automation"]
    )
    chrome_options.add_experimental_option("useAutomationExtension", False)

    # å¯ä»¥ä¼ªè£…ä¸€ä¸‹ UAï¼ˆå¯é€‰ï¼‰
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/122.0 Safari/537.36"
    )

    service = Service(CHROMEDRIVER_PATH)
    driver = webdriver.Chrome(service=service, options=chrome_options)

    # è®© webdriver æ ‡å¿—å˜ä¸º undefinedï¼Œé™ä½Žè¢«è¯†åˆ«ä¸ºè‡ªåŠ¨åŒ–çš„æ¦‚çŽ‡
    driver.execute_cdp_cmd(
        "Page.addScriptToEvaluateOnNewDocument",
        {
            "source": """
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            """
        },
    )

    # é€‚å½“è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶ï¼Œé˜²æ­¢æŸäº›é¡µé¢è¿‡é•¿æ—¶é—´æ— å“åº”
    driver.set_page_load_timeout(15)

    return driver


def search_official_site(driver, school_name: str) -> str:
    """
    ç”¨ Selenium æ‰“å¼€ç™¾åº¦æœç´¢ç»“æžœé¡µï¼Œ
    åœ¨é¡µé¢ä¸­æ‰¾ä¸€ä¸ªæœ€åƒå®˜ç½‘çš„é“¾æŽ¥ hrefï¼ˆä¸åœ¨ Selenium ä¸­è·³è½¬ï¼‰ï¼Œ
    è¿”å›žè¿™ä¸ª hrefï¼ˆå¯èƒ½æ˜¯ç™¾åº¦è·³è½¬ï¼Œä¹Ÿå¯èƒ½å·²ç»æ˜¯çœŸå®žå®˜ç½‘ï¼‰ã€‚
    """
    query = f"{school_name} å®˜ç½‘"
    search_url = "https://www.baidu.com/s?wd=" + quote(query)

    print("  æœç´¢ URL:", search_url)
    driver.get(search_url)
    # å¦‚å‡ºçŽ°éªŒè¯ç ï¼Œå¯åœ¨è¿™é‡Œæ‰‹åŠ¨å¤„ç†åŽå›žè½¦ï¼ˆå¯å–æ¶ˆæ³¨é‡Šï¼‰ï¼š
    # input("âš ï¸ å¦‚å‡ºçŽ°ç™¾åº¦éªŒè¯ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­å¤„ç†åŽå›žè½¦ç»§ç»­ï¼š")

    time.sleep(3.0)  # ç­‰é¡µé¢ç¨³å®š

    # æŠ“æ‰€æœ‰æ ‡é¢˜é‡Œçš„é“¾æŽ¥ï¼ˆæ¡Œé¢ç‰ˆç™¾åº¦é€šå¸¸åœ¨ h3/h2 ä¸‹ï¼‰
    links = driver.find_elements(By.CSS_SELECTOR, "h3 a, h2 a")
    if not links:
        print("  â›” æ²¡æ‰¾åˆ°ä»»ä½•æ ‡é¢˜é“¾æŽ¥")
        return ""

    # è¿‡æ»¤æŽ‰æ˜Žæ˜¾ä¸æ˜¯å®˜ç½‘çš„ç»“æžœ
    bad_keywords = ["ç™¾åº¦ç™¾ç§‘", "ç™¾åº¦çŸ¥é“", "è´´å§", "çŸ¥ä¹Ž", "å¾®åš", "è±†ç“£"]

    candidate_href = None

    for a in links:
        try:
            text = a.text.strip()
            href = a.get_attribute("href") or ""
        except Exception:
            continue

        if not href:
            continue
        if any(bad in text for bad in bad_keywords):
            continue

        # æ ‡é¢˜é‡ŒåŒ…å«å­¦æ ¡å / â€œå®˜ç½‘â€ï¼Œä¼˜å…ˆè®¤ä¸ºæ˜¯å®˜ç½‘
        if (school_name[:2] in text) or ("å®˜ç½‘" in text) or (school_name in text):
            candidate_href = href
            print("  é€‰æ‹©é“¾æŽ¥æ ‡é¢˜ï¼š", text)
            break

    # å¦‚æžœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œå°±é€€è€Œæ±‚å…¶æ¬¡ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æžœ
    if not candidate_href:
        first = links[0]
        candidate_href = first.get_attribute("href") or ""
        print("  å›žé€€ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æžœé“¾æŽ¥")

    print("  åˆæ­¥å€™é€‰ href:", candidate_href)
    return candidate_href


# ================== ä¸»æµç¨‹ ==================


def main():
    # 1. è¯»å–æ•°æ®ï¼šå¦‚æžœå·²æœ‰ç»“æžœæ–‡ä»¶ï¼Œä»Žç»“æžœæ–‡ä»¶æŽ¥ç€è·‘ï¼›å¦åˆ™ä»Ž Step1 æ–‡ä»¶å¼€å§‹
    if Path(OUTPUT_FILE).exists():
        print(f"ðŸ” æ£€æµ‹åˆ°å·²æœ‰ç»“æžœæ–‡ä»¶ï¼š{OUTPUT_FILE}ï¼Œå°†ä»Žä¸­æ–­å¤„ç»§ç»­ã€‚")
        df = pd.read_excel(OUTPUT_FILE)
    else:
        print(f"ðŸ†• æœªå‘çŽ°ç»“æžœæ–‡ä»¶ï¼Œä»Ž {INPUT_FILE} å¼€å§‹æ–°ä¸€è½®é‡‡é›†ã€‚")
        df = pd.read_excel(INPUT_FILE)
        if "official_site" not in df.columns:
            df["official_site"] = ""

    # 2. ç¡®ä¿æœ‰ school_name åˆ—
    if "school_name" not in df.columns:
        raise ValueError(
            f"åˆ— 'school_name' ä¸åœ¨å½“å‰æ•°æ®ä¸­ï¼Œè¯·æ£€æŸ¥ {INPUT_FILE} / {OUTPUT_FILE}ã€‚"
        )

    # 3. åˆå§‹åŒ–æµè§ˆå™¨
    driver = init_driver()

    # 4. éåŽ†å­¦æ ¡ï¼Œæ”¯æŒæ–­ç‚¹ç»­è·‘
    total = len(df)
    for idx, row in df.iterrows():
        school = str(row["school_name"])

        # å·²ç»æœ‰å®˜ç½‘çš„è·³è¿‡
        if isinstance(row.get("official_site", ""), str) and row.get(
            "official_site", ""
        ).strip():
            print(
                f"[è·³è¿‡] {idx + 1}/{total} {school} å·²æœ‰å®˜ç½‘ï¼š{row['official_site']}"
            )
            continue

        print(f"\n=== {idx + 1}/{total}: æ­£åœ¨å¤„ç† {school} ===")

        # 4.1 å…ˆä»Žç™¾åº¦ç»“æžœé¡µæ‹¿åˆ°ä¸€ä¸ªå€™é€‰ href
        try:
            raw_url = search_official_site(driver, school)
        except Exception as e:
            print(f"âŒ æœç´¢ {school} å¤±è´¥: {e}")
            raw_url = ""

        # 4.2 å†ç”¨ requests åœ¨åŽå°è§£æžçœŸå®žå®˜ç½‘ï¼ˆè·Ÿè¸ª 302ï¼‰
        url = resolve_real_url(raw_url)

        # 4.3 å†™å…¥ DataFrameï¼Œå¹¶ç«‹å³ä¿å­˜åˆ° OUTPUT_FILE
        df.at[idx, "official_site"] = url
        print(f"âž¡ï¸  è®°å½•å®˜ç½‘ï¼š{url}")

        df.to_excel(OUTPUT_FILE, index=False)

        # 4.4 éšæœºç­‰å¾…ï¼Œæ¨¡æ‹ŸçœŸäººæ“ä½œï¼Œé™ä½Žè¢«é£ŽæŽ§å‡ çŽ‡
        time.sleep(random.uniform(5.0, 10.0))

    driver.quit()
    print(f"\nâœ… Selenium ç‰ˆæœ¬é‡‡é›†å®Œæˆï¼ç»“æžœå·²ä¿å­˜åˆ°ï¼š{OUTPUT_FILE}")


def run_step2() -> None:
    """Run Selenium crawling to collect official site and search results."""
    main()


if __name__ == "__main__":
    run_step2()
